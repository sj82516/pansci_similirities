本文出處：Think Again: Big Data
譯者：Leonard Chien
「海量資料」是當今最流行的用語，也是科技界對世上各種棘手難題的萬用解答，意指藉由分析龐大資訊後，歸納出模式、精闢見解，並預測複雜問題的答案，聽來或許有些無趣，但無論是阻止恐怖份子、終結貧窮、拯救地球，海量資料支持者都深信可迎刃而解。
在《Big Data: A Revolution That Will Transform How We Live, Work, and Think》一書中，兩位作者寫道，「對於氣候變遷、根除疾病、促進良好治理與經濟發展等全球迫切問題，海量資料均可提供部分答案，為社會提供眾多好處」。
只要握有足夠數據，例如iPhone內部資料、雜貨店購物內容、網路交友檔案、全國匿名醫療紀錄，電腦運算即可拆解這些原始資料，從中挖掘出無數見解。美國歐巴馬政府亦傾力投入，於5月9日「首開先例」，公開「過往無法取用或管理的資料」，供企業家、研究人員及大眾使用。
歐巴馬總統表示，「我們希望促成更多民間創新與發現，因此史上首次釋出大量美國資料，開放人們輕鬆取用，優秀企業家也已開發出眾多用途」。
可是海量資料的威力是否名實相符？在龐大電腦數據裡，是否真能揭露人類行為的秘密？《外交政策》雜誌邀請麻省理工學院「公民媒體中心」成員Kate Crawford，說明數字背後的真相。－編按
「只要資料足夠，數字自會說話。」
不可能。海量資料支持者希望我們相信，在程式碼字裡行間與巨大資料庫內，必有客觀及通用的見解，能解釋人類行為模式，包括消費情況、犯罪或恐怖主義行動、健康習慣、員工產能等，但他們卻總不願正視缺點。數字不會說話，資料不論規模大小，仍受人類設計限制，Apache Hadoop軟體架構等海量資料工具亦無法排除偏斜、落差與假設錯誤。當海量資料試圖歸納社會狀態，這些因素影響格外顯著，但我們卻常誤以為分析結果比個人意見更客觀。其實海量資料、個人觀感及體驗皆然，充滿偏見及盲點，可是許多人卻以為資料量越大就代表品質越好的資料，也以為「相關」與「因果」一樣好。
例如社群媒體常成為海量資料分析主題，其中也確實充斥大量資訊，據稱從Twitter資料裡可見，人們離家愈遠愈開心，且情緒在每週四晚上最低落。可是我們必須懂得質疑資料背後真正的涵義，例如「皮猶研究中心」指出，美國只有16%的成年網路用戶使用Twitter，亦無法如實代表社會結構，通常年紀較輕、較集中於都會區。此外，許多Twitter帳號均為自動機器人或假檔案，近期估計總數可能高達2000萬，因此討論如何從Twitter分析輿論之前，得先釐清這些反應究竟來自真人或電腦演算式。
縱然各位相信絕大多數Twitter用戶均為真人，偏見依然存在，例如為分析2013年澳洲網球公開賽中，人們在社群媒體對哪些選手「看法最佳」，IBM透過「社會觀感指數」，大量分析Twitter訊息，結果由Victoria Azarenka奪冠，但許多訊息提到她時，都在批評她濫用傷停時間，如此看來，很難相信IBM的演算式確能反映現實。
即便排除不良資料問題，演算式本身亦有偏見，新聞彙整網站取用你我的個人偏好與瀏覽紀錄，編排出用戶感興趣的最新消息，其中假設頻率與重要性呈正比，或個人社群最常分享的資訊，也必定與你興趣相符。演算式過濾龐大資料時，也訂定呈現世界的原則，一般用戶不會感受到這些規則，可是大大左右民眾觀點。
不少資訊工程專家正在努力解除疑慮，Ed Felten為普林斯頓大學教授，曾為美國聯邦貿易委員會首席科技專家，最近發起一項計畫，測驗各項演算式的偏見，尤其是美國政府也運用演算式評估個人，例如聯邦調查局與運輸安全局即彙整多項官方海量資料，列出航空旅客黑名單，做為飛安制度之用。
「海量資料可提高城市智慧及效能。」
仍有上限。海量資料可提供珍貴見解，協助改善城市，但也僅止於此，由於資料生成與收集過程並不均等，其中會出現「信號問題」，造成有些民眾及社區遭到漠視或代表性不足，若以海量資料處理城市規劃問題，必須仰賴官員同時瞭解資料及其侷限。
例如美國波士頓的Street Bump應用程式裡，收集行經坑洞的駕駛人智慧型手機資料，能以低成本途徑收集資訊，類似應用程式也與日俱增，可是城市若完全依賴智慧型手機用戶提供資料，等於自動排除部分樣本，某些社區內智慧型手機用戶比例若較低，通常年齡層較高，經濟條件也較弱勢，因此遭到排擠。波士頓市政單位盡力想彌補潛在資料缺口，但假若官員對此警覺性較低，就可能忽略這項問題，導致資源分配不均，進一步擴大既有社會失衡現象。2012年Google的流感趨勢預測中，就曾犯下相同錯誤，嚴重高估年度流感比例，證明若依賴有瑕疵的海量資料，將大大影響公共服務與政策。
「開放政府」計畫將公部門資料張貼於網路上，如Data.gov或美國白宮「開放政府計畫」，也可能面臨相同問題，資料增加未必可改善透明度、責信等政府功能，必須搭配公眾參與機制，政府也得懂得如何詮釋資料，再運用適當資料因應。這些條件都不簡單，況且目前優秀的資料科學家也不足，各大學仍在趕緊劃定學科領域、編寫課程，希望能滿足需求。
人權團體也希望運用海量資料，瞭解各種衝突和危機，但資料與分析品質同樣令人存疑，麥克阿瑟基金會最近核准17.5萬美元的獎助金，由卡內基梅隆大學人權科學中心投入為期18個月的研究，分析海量資料數據如何改變人權運動發展，例如開發「可信度測驗」，以驗證張貼於Crisis Mappers、Ushahidi、Facebook、YouTube等網站的人權侵害控訴真偽。該中心主任Jay D. Aronson指出，「包括學界及人權組織的消息來源，以及資料使用情況，都產生嚴重問題，有了這些新科技之後，對於通報者的人身安全是利或弊，許多時候仍不得而知」。
「海量資料對各個社會族群一視同仁。」
未必如此。海量資料號稱客觀，因為原始資料似乎能排除社會偏見，故可減少歧視少數族群的機率，讓大規模分析避免族群歧視，但海量資料之所以存在，就是為了將個人劃入族群之中，再解釋各族群行為有何異同。例如近期一篇論文才提到，在海量資料基因體研究內，科學家如何讓個人立場左右研究方向。
如Alistair Croll所言，人們可能運用海量資料製造價格歧視，引起眾多公民權疑慮，在「個人化」名義下，海量資料卻可能用來針對特定社會族群，給予不一樣的待遇，法律通常禁止企業與個人出現此種歧視行為。企業購買網路廣告宣傳信用卡時，可能依據家戶所得或信貸紀錄，挑選特定目標群眾，導致他人完全無從得知該項優惠。Google甚至握有浮動設定內容價格的專利，例如你過往消費紀錄若顯示，可能花高價購買鞋子，下回在網路上打算買鞋時，搜尋結果也將傾向高價品。雇主如今也希望在人力資源方面運用海量資料，完全透過分析電腦使用習慣，評估如何提高員工生產力，而員工可能對這些資料與用途毫不知情。
其他因素也可能產生歧視，例如《紐約時報》曾報導，量販店Target多年前便已開始收集消費者分析數據，如今消費紀錄相當龐大，在某些情況下，甚至可單純根據消費品項歴史，判斷該名女性顧客是否懷孕，可靠度甚至高達87%。儘管該公司代表在報導內強調，這些資料是用來改善對準媽媽的行銷策略，可是這種手段很容易用於歧視，大大影響社會平等與隱私。
英國劍橋大學最近發表一項海量資料研究，運用58000則Facebook網站的按讚紀錄，預測用戶相當敏感的個人資訊，例如性傾向、族裔、宗教與政治立場、個性、智商、幸福程度、菸毒習慣、父母婚姻狀況、年齡、性別等，記者Tom Foremski指出，「取得如此敏感的資訊後，可能遭雇主、房東、政府機關、教育機構、民間組織利用，刻意歧視與懲罰個人，且對方完全無法抵抗」。
海量資料也會影響執法，無論是華府或德拉瓦州的新堡郡，警方都開始採用海量資料「預防巡邏」模型，希望有助調查懸案，甚至避免犯罪發生，可是若將警力集中在海量資料判斷出的潛在犯罪熱點，卻可能強化某些社會族群的污名，認為他們較可能犯案，也等於將區域警力落差視為常態。一名警官曾表示，雖然預防巡邏演算式刻意避免種族、性別等分類，但若隨意使用這些系統，又未察覺差別待遇可能造成的後果，將會造成「警察與社區關係惡化，欠缺程序正義、遭指控種族歧視，也威脅執法基礎」。
「海量資料屬匿名，不會侵犯隱私。」
大錯特錯。許多海量資料供應者都盡其所能，希望避免個人身分曝光，但風險卻仍存在，大量手機資料或許看似匿名，但近期研究歐洲150萬手機用戶資料顯示，只要四點參考點，即可辨識95%的民眾。研究人員提到，人們往來城市路徑有其獨特性，又能以大量公開資料組推論，讓隱私「疑慮愈來愈強烈」。拜Alessandro Acquisti等學者之賜，只要交叉分析公開資料，即可預測個人社會安全碼。
可是海量資料的隱私問題，不只是一般身分辨識風險，目前醫療資料轉售給分析公司後，可能用來追蹤個人身分，許多人都在討論個人化醫學，希望藥品及其他療程能夠針對個人需求，讓治療效果如同取自個人DNA。此舉可改善療效，但基本上得辨識人體分子和基因，假若使用不當或外流，可能造成高風險。儘管RunKeeper、Nike+等個人健康資料收集裝置迅速增加，尚無太多海量資料實際改善醫療服務的案例。
海量資料能源計畫亦收集各種私密資訊，智慧電力網即為一例，分析龐大消費者用電量資料後，希望改善住家與企業能源配送效能，雖然前景可期，隱私風險也很高，不僅可預測能源用量及需用時間，亦包括住戶在家中動向及行為的時刻資訊，例如何時洗澡、客人何時離開、何時關燈睡覺。
這些充滿個人資訊的海量資料，自然成為駭客及洩露情報者下手的目標，「維基解密」為近期釋出海量資料的知名案例，此外，英國境外金融產業資料最近也大量曝光，顯見人們不論貧富，個人資料都可能公諸於世。
「海量資料是科學的未來。」
部分屬實，但仍在持續發展。海量資料確實提供科學發展的新方向，例如在發現希格斯玻子的過程中，歐洲核子研究組織CERN即運用Hadoop分散式檔案系統管理資料，可是除非我們正視及處理海量資料反映人類生活的缺陷，就可能依據錯誤假設做出重大公共政策及企業決定。
為處理此事，資料科學家開始與社會科學家合作，因為後者處理資料的經驗相當豐富，包括評估來源、資料收集方式、使用倫理等，發掘結合海量資料策略與少量資料研究的新方式，不只是需要焦點團體、A/B測試等廣告行銷策略。新混成方式能思考行為背後的成因，而不只是計算事物發生頻率，故除了資訊檢索與機器學習，也需要社會學分析及民族誌學見解。
科技公司很早就明白，社會科學家能協助解釋消費者與產品互動的方式，例如PARC就曾聘請知名人類學家Lucy Suchman，資訊工程、統計、社會科學等領域未來將更密切合作，不僅是為測試彼此研究所得，也要以更嚴謹的態度提出各種問題。
每天各方都收集關於你我的大量資料，包括Facebook點擊習慣、衛星定位資料、醫療處方、Netflix影片觀賞紀錄等，我們必須盡早決定可託付資料的對象及用途。資料永遠不可能中立，也很難匿名，但我們可運用各項專業領域，以察覺種種偏見、落差與假設，進而面對有關隱私及公平性的新挑戰。
本文原發表於譯者部落格「我書」
2017 年泛知識節 早腦人必搶的早鳥優惠開跑啦！
「3 大領域 x 150 場分享、體驗、工作坊 x 200 個意見領袖 x 1000 個參與者」2017 年兩岸三地最大知識饗宴 – “泛・知識節" 早鳥票開賣啦！
由泛科知識旗下 PanSci 科學新聞網、 娛樂重擊 Punchline、PanX 泛科技新聞網聯合超強協力夥伴，邀你在兩天內火拼知識，替自己的大腦做個版本升級。11月 11&12 日到泛．知識節直搗知識核心，挑戰與創造未知 ∞ 種可能！手腳迅速，眼光精準的早腦人如你，還不速速搶下早鳥優惠及獨家周邊商品！（購票還贈 TAAZE 讀冊生活折價卷）
>>早鳥優惠只到 10/27<<